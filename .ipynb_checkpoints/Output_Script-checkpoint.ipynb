{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Produce an Output from the Models\n",
    "Presumably this will need to be transferred to a script-based format but this is the code to turn an input image into a controller action\n",
    "\n",
    "## Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Flatten, Input, Dense, Dropout, Lambda, Reshape, MaxPooling2D, LSTM, Reshape\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables for potential modification\n",
    "\n",
    "`img_height/width`: this and all below variables should be the same for the trained images and input images\n",
    "\n",
    "`z_len`: the length of the image compression made by the encoder\n",
    "`a_len`: the length of the action vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 128\n",
    "img_width = 128\n",
    "num_channels = 1\n",
    "input_shape = (img_height, img_width, num_channels)\n",
    "z_len = 2048\n",
    "a_len = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architectures\n",
    "\n",
    "# VAE\n",
    "\n",
    "load the vae (have to make the architecture again, make sure the code below matches the code in the Data Prepper/VAE Trainer)\n",
    "\n",
    "\n",
    "# Encoder\n",
    "`latent_dim`: changing this will make the model exponentially larger or smaller\n",
    "\n",
    "`x`: the model (saved in x)\n",
    "\n",
    "`conv_shape`: Shape of conv to be provided to decoder\n",
    "\n",
    "`z_mu` and `z_sigma`: Two outputs, for latent mean and log variance (std. dev.) Use these to sample random variables in latent space to which inputs are mapped. \n",
    "\n",
    "`sample_z` Function: REPARAMETERIZATION TRICK\n",
    "- Define sampling function to sample from the distribution\n",
    "- Reparameterize sample based on the process defined by Gunderson and Huang\n",
    "- into the shape of: mu + sigma squared x eps\n",
    "- This is to allow gradient descent to allow for gradient estimation accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2048\n",
    "\n",
    "input_img = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(64, 3, padding='same', activation='relu')(input_img)\n",
    "x = MaxPooling2D((2,2), padding='same')\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2,2), padding='same')\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D((2,2), padding='same')\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "conv_shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(latent_dim*2, activation='relu')(x)\n",
    "\n",
    "z_mu = Dense(latent_dim, name='latent_mu')(x)\n",
    "z_sigma = Dense(latent_dim, name='latent_sigma')(x)\n",
    "\n",
    "def sample_z(args):\n",
    "    z_mu, z_sigma = args\n",
    "    eps = K.random_normal(shape=(K.shape(z_mu)[0], K.int_shape(z_mu)[1]))\n",
    "    return z_mu + K.exp(z_sigma / 2) * eps\n",
    "\n",
    "z = Lambda(sample_z, output_shape=(latent_dim,), name='z')([z_mu, z_sigma])\n",
    "\n",
    "encoder = Model(input_img, [z_mu, z_sigma, z], name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder \n",
    "\n",
    "### decoder takes the latent vector as input: `decoder_input`\n",
    "\n",
    "First `x` Layer: Need to start with a shape that can be remapped to original image shape as we want our final utput to be same shape original input. So, add dense layer with dimensions that can be reshaped to desired output shape\n",
    "\n",
    "Second `x` Layer: reshape to the shape of last conv. layer in the encoder, so we can \n",
    "\n",
    "Third `x` Layer: upscale (conv2D transpose) back to original shape use Conv2DTranspose to reverse the conv layers defined in the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
